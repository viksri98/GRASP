#' GRASP test statistics
#'
#' This function will generate the GRASP test statistics defined as $V_{n,L}$ in Algorithm 2 from the original paper, in the distribution free setting with score function T(x,w) = w
#' @param y n labels $y_j \in \{0, 1\}$ as a vector
#' @param model the model $\hat{\eta}:\chi \to [0,1]$ as a vector of predicted labels, the result of running the model on each x_j.
#' @param L an integer greater than or equal to 1, default to 50
#' @export
fgrasp_statistic <- function(y, model, L=50){
		# get the number of data points
		n <- length(y)
		# Initialize $V_{n,L}$ vector
		VnL <- rep(0,L)
		# Initialize w vector
		w = rep(0,n)
		# Initialize labels vector. This will correspond to the label for w[j]
		labels = rep(0,n)
		for(j in 1: n){
				if(y[j] == 1){
						w[j] <- runif(1,min=0,max=model[j])
				}else{
						w[j] <- runif(1,min=model[j],max=1)
				}
				for(Lj in 1:L){
						if((Lj-1)/L <= w[j] & w[j] <= Lj/L){
								labels[j] <- Lj
						}
				}
		}
		for(l in 1:L){
				VnL[l] <- sum(labels == l)
		}
		return(VnL)
}

#' Asymptotic test statistic (Simple)
#'
#' This function will generate the asymptotic test statistic $U_0^{asym}$, with a tolerance of 0.
#' This is the case covered with detail in the original GRASP paper.
#' @param VnL the output vector of fgrasp_statistic()
#' @param n the number of datapoints processed to make this statistic
#' @export
u_asym_0 <- function(VnL, n){
		L <- length(VnL)
		u <- L/n * sum((VnL - n/L)^2)
		return(u)
}

#' Finite test statistic (Simple)
#'
#' This function will generate the finite test statistic $U_0^{finite}$, with a tolerance of 0.
#' This is the case covered with detail in the original GRASP paper.
#' @param VnL the output vector of fgrasp_statistic()
#' @param n the number of datapoints processed to make this statistic
#' @export
u_finite_0 <- function(VnL, n){
		return(u_asym_0(VnL,n)/2)
}

#' Total Variation Distance test statistic
#'
#' This function will return the initial hypothesis test statistic generated by equation(3) in the paper, with $f(t) = 1/2|t-1|$.
#' @param eta the vector of labels in the test data
#' @param eta_hat the vector of labels predicted by the model
#' @export
hypothesis_tv <- function(eta, eta_hat){
		n <- length(eta)
		return(1/n*sum(abs(eta_hat-eta)))
}

#' KL divergence test statistic
#'
#' This function will return the initial hypothesis test statistic generated by equation(3) in the paper, with $f(t) = t log t$.
#' @param eta the vector of labels in the test data
#' @param eta_hat the vector of labels predicted by the model
#' @export
hypothesis_kl <- function(eta, eta_hat){
		n <- length(eta)
		ce <- -1/n * sum(eta * log(eta) + (1-eta) * log(eta))
		ce_hat <- -1/n * sum(eta * log(eta_hat) + (1-eta) * log(1-eta_hat))
		return(ce_hat - ce)
}

#' Hellinger Distance test statistic
#'
#' This function will return the initial hypothesis test statistic generated by equation(3) in the paper, with $f(t) = (\sqrt{t} - 1)^2$.
#' @param eta the vector of labels in the test data
#' @param eta_hat the vector of labels predicted by the model
#' @export
hypothesis_h <- function(eta, eta_hat){
		n <- length(eta)
		return(1/n * sum((sqrt(eta) - sqrt(eta_hat))^2 + (sqrt(1-eta) - sqrt(1-eta_hat))^2))
}

#' Total Variation Distance
#'
#' This function returns the total variation distance of t
#' @param t the input parameter
#' @export
tv <- function(t){
		return(1/2 * abs(t-1))
}

#' KL Divergence
#'
#' This function returns the KL divergence of t
#' @param t the input parameter
#' @export
kl <- function(t){
		return(t*log(t))
}

#' Hellinger Distance
#'
#' This function returns the hellinger distance of t
#' @param t the input parameter
#' @export
h <- function(t){
		return((sqrt(t) - 1)^2)
}

#' Asymptotic Objective Function
#'
#' This function returns the asymptotic objective function that we can optimize over
#' @param vnl the vnl statistic generated by fgrasp_statistic
#' @param n the number of samples
#' @export
gen_asym <- function(vnl, n){
		u <- function(x){
				return(1/n * sum((vnl-n*x)^2/x))
		}
		return(u)
}

#' Finite Objective Function
#'
#' This function returns the finite objective function that we can optimize over
#' @param vnl the vnl statistic generated by fgrasp_statistic
#' @param n the number of samples
#' @export
gen_finite <- function(vnl, n){
		u <- function(x){
				return(1/n * sum((vnl-n*x)^2/(x+1/L)))
		}
		return(u)
}

#' Constraint Generator
#'
#' This function returns a function which acts as the constraint 1/L*sum(f(LP)) <= tau
#' @param L the number of categories used in the algorithm L
#' @param f the function f to be used from the algorithm
#' @export
gen_constraint <- function(L, f){
		con <- function(p){
				return(1/L * sum(f(L * p)))
		}
		return(con)
}

#' Finite test statistic
#'
#' This function will generate the Finite test statistic $U_t^{finite}$, using the solver alabama
#' If t=0, then call u_finite() instead
#' @import ROI
#' @import ROI.plugin.alabama
#' @param VnL the output vector of fgrasp_statistic()
#' @param n the number of data points processed to make this statistic
#' @param t the tolerance allowed
#' @param f the convex, continuous function which defines the f-divergence tested. default to tv
#' @export
u_finite <- function(VnL, n, t, f=tv){
		if(t == 0){
				return(u_finite(VnL, n))
		}
		L <- length(VnL)
		objective <- F_objective(gen_finite(VnL, n), n=L)
		constraints <- F_constraint(F=list(sum, gen_constraint(L,f)), dir=c("==", "<="), rhs=c(1,t))
		problem <- OP(objective, constraints)
		sol <- ROI_solve(problem, solver="alabama", start=rep(1/L, L))
		return(sol$objval)
}

#' Asymptotic test statistic
#'
#' This function will generate the asymptotic test statistic $U_t^{asym}$, using the solver alabama
#' If t=0, then call u_asym() instead
#' @import ROI
#' @import ROI.plugin.alabama
#' @param VnL the output vector of fgrasp_statistic()
#' @param n the number of data points processed to make this statistic
#' @param t the tolerance allowed
#' @param f the convex, continuous function which defines the f-divergence tested. default to tv
#' @export
u_asym <- function(VnL, n, t, f=tv){
		if(t == 0){
				return(u_asym_0(VnL, n))
		}
		L <- length(VnL)
		objective <- F_objective(gen_asym(VnL, n), n=L)
		constraints <- F_constraint(F=list(sum, gen_constraint(L,f)), dir=c("==", "<="), rhs=c(1,t))
		problem <- OP(objective, constraints)
		sol <- ROI_solve(problem, solver="alabama", start=rep(1/L, L))
		return(sol$objval)
}

#' Model-X GRASP statistics
#'
#' This function is a variation of fgrasp_statistic() which uses joint variation data in order to construct the statistics VnL.
#' We assume that the data is distributed over random normal.
#' @param x a matrix of samples, where rows are samples and columns are features
#' @param y the vector of labels from the dataset
#' @param model the model as a function from Chi -> [0,1].
#' @param score the score function, default to the model-agnostic score function
#' @param L the number of categories for VnL, default to 50, must be greater than or equal to 2
#' @export
xgrasp_statistic <- function(x, y, model, score, L=50){
		M <- L-1
		# calculate y_hat
		y_hat <- apply(x, 1, model)
		# get the number of data points
		n <- length(y)
		# Initialize $V_{n,L}$ vector
		VnL <- rep(0,L)
		# Initialize R vector
		R = rep(0,n)
		# Initialize labels vector. This will correspond to the label for R[j]
		labels = rep(0,n)
		for(j in 1: n){
				# Set w for each iteration
				if(y[j] == 1){
						w <- runif(1,min=0,max=y_hat[j])
				}else{
						w <- runif(1,min=y_hat[j],max=1)
				}
				# Generate random wtilde
				w_tilde <- runif(M, 0, 1)
				# Generate random samples from Px
				xtilde <- matrix(rep(0, M * L), nrow=M, ncol=L)
				for(i in 1:M){
						xtilde[i,] <- rnorm(L, 0, 1)
				}
				# Initialize scores vector
				T <- rep(0, M+1)
				T[1] <- score(x[j,], w)
				for(k in 1:M){
						T[k+1] <- score(xtilde[k,], w_tilde[k])
				}
				# Find rank of T[1] in the T array
				Tj <- T[1]
				T <- sort(T)
				R[j] <- which(T == Tj)[[1]]
				# Find where R[j] fits
				for(Lj in 1:L){
						if(Lj-1 <= R[j] & R[j] <= Lj){
								labels[j] <- Lj
						}
				}
		}
		for(l in 1:L){
				VnL[l] <- sum(labels == l)
		}
		return(VnL)
}
